{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing1 import PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billmurray\n",
      "billnye\n",
      "obama\n",
      "Dataset loaded successfully.\n",
      "Preprocessing Done. Summary:\n",
      "Images train : (159, 368, 368, 3)\n",
      "Labels train : (159,)\n",
      "Images test  : (0,)\n",
      "Labels test  : (0,)\n",
      "Unique label : [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "dataset = PreProcessing('./data_src', 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 368, 3)\n",
      "(368, 368, 3)\n",
      "(368, 368, 3)\n"
     ]
    }
   ],
   "source": [
    "anchors = []\n",
    "positives = []\n",
    "negatives = []\n",
    "n = 200\n",
    "for _ in range(n):\n",
    "    anchors.append(dataset.generate_triplets()[0])\n",
    "    positives.append(dataset.generate_triplets()[1])\n",
    "    negatives.append(dataset.generate_triplets()[2])\n",
    "print((anchors[1].shape))\n",
    "print((anchors[2].shape))\n",
    "print((anchors[3].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 368, 3)\n",
      "(368, 368, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def train_test_split(arr, p=.9):\n",
    "    test = []\n",
    "    train = []\n",
    "    for i in range(len(arr)):\n",
    "        if i < len(arr)*.9: train.append(arr[i])\n",
    "        else: test.append(arr[i])\n",
    "    return np.array(train), np.array(test)\n",
    "#     return train, test\n",
    "\n",
    "anchor_train, anchor_test = train_test_split(anchors)\n",
    "print((anchor_train[1].shape))\n",
    "print((anchor_train[3].shape))\n",
    "positive_train, positive_test = train_test_split(positives)\n",
    "negative_train, negative_test = train_test_split(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "def create_base_network(in_dims):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    model.add(Conv2D(256,(5,5),padding='same',activation='relu',name='conv2'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(4,name='embeddings'))\n",
    "    # model.add(Dense(600))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape =  Tensor(\"merged_layer/concat:0\", shape=(None, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "anchor_input = Input((368, 368, 3), name='anchor_input')\n",
    "positive_input = Input((368, 368, 3), name='positive_input')\n",
    "negative_input = Input((368, 368, 3), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network([368,368,3])\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer=adam_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 368, 368, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 368, 368, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 368, 368, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4)            9505540     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 12)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 9,505,540\n",
      "Trainable params: 9,505,540\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "anchor_train = anchor_train.reshape(-1,368,368,3)\n",
    "Positive_train = positive_train.reshape(-1,368,368,3)\n",
    "Negative_train = negative_train.reshape(-1,368,368,3)\n",
    "Anchor_test = anchor_test.reshape(-1,368,368,3)\n",
    "Positive_test = positive_test.reshape(-1,368,368,3)\n",
    "Negative_test = negative_test.reshape(-1,368,368,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 368, 368, 3)\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Anchor = anchor_train.reshape(-1,368,368,1)\n",
    "# Positive = X_train[:,1,:].reshape(-1,368,368,3)\n",
    "# Negative = X_train[:,2,:].reshape(-1,368,368,3)\n",
    "# Anchor_test = X_test[:,0,:].reshape(-1,368,28,1)\n",
    "# Positive_test = X_test[:,1,:].reshape(-1,28,28,1)\n",
    "# Negative_test = X_test[:,2,:].reshape(-1,28,28,1)\n",
    "# anchor_train = np.array(anchor_train)\n",
    "# Y_dummy = np.empty((anchor_train.shape,300))\n",
    "# Y_dummy2 = np.empty((anchor_test.shape,1))\n",
    "# print((anchor_train[1].shape))\n",
    "# print((anchor_train[3].shape))\n",
    "# def create_y_dummy(arr):\n",
    "#     dummy = []\n",
    "#     for i in range(len(arr)):\n",
    "#         dummy.append(np.empty(arr[i].shape))\n",
    "#     return dummy\n",
    "\n",
    "Y_dummy = np.empty((anchor_train.shape[0],12))\n",
    "Y_dummy2 = np.empty((anchor_test.shape[0],12))\n",
    "print(anchor_test.shape)\n",
    "# model.fit([anchor_train,positive_train,negative_train],y=Y_dummy,validation_data=([anchor_test,positive_test,negative_test],Y_dummy2), batch_size=512, epochs=500)\n",
    "model.fit([anchor_train,positive_train,negative_train],y=Y_dummy,validation_data=([anchor_test,positive_test,negative_test],Y_dummy2), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Classifier_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-033e81e08d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mClassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Classifier_model' is not defined"
     ]
    }
   ],
   "source": [
    "Classifier_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
